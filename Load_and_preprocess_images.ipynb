{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fc8de5-0d8a-453e-8098-b40b3d406c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# https://www.tensorflow.org/tutorials/load_data/images\n",
    "#\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f7b4ec-46c8-4610-be01-7a3344fd33c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbd4eed-d617-4fca-89d9-f4cbf9c2803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "archive = tf.keras.utils.get_file(origin=dataset_url, extract=True)\n",
    "data_dir = pathlib.Path(archive + \"/flower_photos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aa6366-b9b5-4631-a40f-b0059811e397",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc109b5-a3cb-49c3-afa0-72597d8b30d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d9f551-72c2-4186-b35b-9ec7e7085d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "roses = list(data_dir.glob('roses/*'))\n",
    "PIL.Image.open(str(roses[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c497df-7362-4b34-8dc4-7e60e9099be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL.Image.open(str(roses[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a256764-803f-451b-8432-0fe52c9e095d",
   "metadata": {},
   "source": [
    "## Load data using a Keras utility\n",
    "Let's load these images off disk using the helpful tf.keras.utils.image_dataset_from_directory utility.\n",
    "\n",
    "### Create a dataset\n",
    "Define some parameters for the loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b070529-e501-473e-bce8-c05e05920ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6cab13-cc5a-48f8-9e04-fff108be535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8741b6e5-67ee-4e95-bf62-11f9e80896f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bcc010-a203-4c4e-a2d9-2ffd1eac52ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0d27f4-b378-4b30-a661-f73e52393c3d",
   "metadata": {},
   "source": [
    "### Visualize the data\n",
    "Here are the first nine images from the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4f01df-1bbd-4100-baf0-a442078f36b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbf9e3d-7a37-4b5e-84e2-16fb586eb211",
   "metadata": {},
   "source": [
    "You can train a model using these datasets by passing them to model.fit (shown later in this tutorial). If you like, you can also manually iterate over the dataset and retrieve batches of images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91943e09-df88-4fbf-bee8-23385ab6a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b46a20-4977-4850-be94-6725b536973f",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82d3069-50fa-4e52-b2a6-f496ddec81fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b13a79-2f51-4ac3-879a-9f1dbe69c52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615d1cf2-cb1d-4894-8caf-a0e5323b604d",
   "metadata": {},
   "source": [
    "### Train a model\n",
    "For completeness, you will show how to train a simple model using the datasets you have just prepared.\n",
    "\n",
    "The Sequential model consists of three convolution blocks (tf.keras.layers.Conv2D) with a max pooling layer (tf.keras.layers.MaxPooling2D) in each of them. There's a fully-connected layer (tf.keras.layers.Dense) with 128 units on top of it that is activated by a ReLU activation function ('relu'). This model has not been tuned in any way—the goal is to show you the mechanics using the datasets you just created. To learn more about image classification, visit the Image classification tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc73976-4cad-4925-9c61-e1e428987637",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Rescaling(1./255),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149bc814-120a-48c4-8081-e9cbf1715239",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2504af-753e-484e-ba63-5811d240f5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65e9b5a-da98-4481-8ff6-31de0b1900be",
   "metadata": {},
   "source": [
    "### Using tf.data for finer control\n",
    "The above Keras preprocessing utility—tf.keras.utils.image_dataset_from_directory—is a convenient way to create a tf.data.Dataset from a directory of images.\n",
    "\n",
    "For finer grain control, you can write your own input pipeline using tf.data. This section shows how to do just that, beginning with the file paths from the TGZ file you downloaded earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce7f74c-beb9-4499-9dc2-8211d7148dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'), shuffle=False)\n",
    "list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1350dfb-8a99-4521-9664-eb6afcab9ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in list_ds.take(5):\n",
    "  print(f.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99401b6-59eb-431b-ab0b-8e815d4b64db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.array(sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c963c8-f115-4c7b-9beb-e730c7708e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = int(image_count * 0.2)\n",
    "train_ds = list_ds.skip(val_size)\n",
    "val_ds = list_ds.take(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f87e58f-68fd-4c00-a59d-99f38f0561f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.data.experimental.cardinality(train_ds).numpy())\n",
    "print(tf.data.experimental.cardinality(val_ds).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bdd2bf-142f-4c98-a795-ad5286ad2cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "  # Convert the path to a list of path components\n",
    "  parts = tf.strings.split(file_path, os.path.sep)\n",
    "  # The second to last is the class-directory\n",
    "  one_hot = parts[-2] == class_names\n",
    "  # Integer encode the label\n",
    "  return tf.argmax(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f8c4d6-76f1-4230-b823-3c08dc1cdb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "  # Convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.io.decode_jpeg(img, channels=3)\n",
    "  # Resize the image to the desired size\n",
    "  return tf.image.resize(img, [img_height, img_width])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbb6c21-8d35-4c20-a86a-8d878775eea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "  label = get_label(file_path)\n",
    "  # Load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_img(img)\n",
    "  return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb12a64f-e204-4a87-9358-6d5ffacb8f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Dataset.map to create a dataset of image, label pairs:\n",
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "train_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7c9889-b954-436e-8eb0-e8ee14d2a36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in train_ds.take(1):\n",
    "  print(\"Image shape: \", image.numpy().shape)\n",
    "  print(\"Label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb0553d-364f-4d69-8bdd-16592d692a95",
   "metadata": {},
   "source": [
    "### Configure dataset for performance\n",
    "To train a model with this dataset you will want the data:\n",
    "\n",
    "- To be well shuffled.\n",
    "- To be batched.\n",
    "- Batches to be available as soon as possible.\n",
    "  \n",
    "These features can be added using the tf.data API. For more details, visit the Input Pipeline Performance guide.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d57556-0ea7-4221-8b4b-1d5c3da62944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_for_performance(ds):\n",
    "  ds = ds.cache()\n",
    "  ds = ds.shuffle(buffer_size=1000)\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "  return ds\n",
    "\n",
    "train_ds = configure_for_performance(train_ds)\n",
    "val_ds = configure_for_performance(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853711a4-bf53-43bc-ab8b-3e296335f4e9",
   "metadata": {},
   "source": [
    "### Visualize the data\n",
    "You can visualize this dataset similarly to the one you created previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46068c2d-3ba4-40e5-87bf-dad46494abbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(train_ds))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "  ax = plt.subplot(3, 3, i + 1)\n",
    "  plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "  label = label_batch[i]\n",
    "  plt.title(class_names[label])\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c89a3c-ec48-443e-a1aa-0f4f009e5273",
   "metadata": {},
   "source": [
    "### Continue training the model\n",
    "You have now manually built a similar tf.data.Dataset to the one created by tf.keras.utils.image_dataset_from_directory above. You can continue training the model with it. As before, you will train for just a few epochs to keep the running time short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baae9a74-2dc9-4e77-b807-c5e2ca956be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe85a89e-ee24-415f-a5da-e9249f34f8f8",
   "metadata": {},
   "source": [
    "## Using TensorFlow Datasets\n",
    "So far, this tutorial has focused on loading data off disk. You can also find a dataset to use by exploring the large catalog of easy-to-download datasets at TensorFlow Datasets.\n",
    "\n",
    "As you have previously loaded the Flowers dataset off disk, let's now import it with TensorFlow Datasets.\n",
    "\n",
    "Download the Flowers dataset using TensorFlow Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cc2d09-f4d7-447d-8d51-293495274c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_ds, val_ds, test_ds), metadata = tfds.load(\n",
    "    'tf_flowers',\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9f63f3-e451-4c02-ad5c-1cfabb4973cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The flowers dataset has five classes:\n",
    "num_classes = metadata.features['label'].num_classes\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088d814c-9fba-40e4-9966-b46fc7e26a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve an image from the dataset:\n",
    "get_label_name = metadata.features['label'].int2str\n",
    "\n",
    "image, label = next(iter(train_ds))\n",
    "_ = plt.imshow(image)\n",
    "_ = plt.title(get_label_name(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b3b9f3-49c1-4517-b72a-c4c521b76b9f",
   "metadata": {},
   "source": [
    "As before, remember to batch, shuffle, and configure the training, validation, and test sets for performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd16f0c7-c4e1-4b06-87fc-b0445fcb2663",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = configure_for_performance(train_ds)\n",
    "val_ds = configure_for_performance(val_ds)\n",
    "test_ds = configure_for_performance(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25561a82-2fc9-4689-9163-b31d84ffd7b3",
   "metadata": {},
   "source": [
    "You can find a complete example of working with the Flowers dataset and TensorFlow Datasets by visiting the [Data augmentation](https://www.tensorflow.org/tutorials/images/data_augmentation) tutorial.\n",
    "\n",
    "## Next steps\n",
    "This tutorial showed two ways of loading images off disk. First, you learned how to load and preprocess an image dataset using Keras preprocessing layers and utilities. Next, you learned how to write an input pipeline from scratch using tf.data. Finally, you learned how to download a dataset from TensorFlow Datasets.\n",
    "\n",
    "For your next steps:\n",
    "\n",
    "- You can learn how to add data augmentation.\n",
    "- To learn more about tf.data, you can visit the tf.data: Build TensorFlow input pipelines guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1220dd77-7b06-48ce-b03a-4ca4ac41cfc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
